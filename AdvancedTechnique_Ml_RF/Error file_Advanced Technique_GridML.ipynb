{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9c28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Libraies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237198da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('insurance_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c7f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e88e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep=dataset[['age', 'bmi', 'children','sex_male', 'smoker_yes']]\n",
    "dep=dataset['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb3570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(indep, dep, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf30b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e34e185a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 1622.1885  41919.097    8944.1151   4391.652    4005.4225   8930.93455\n  9447.25035  7731.85785 11576.13     3757.8448   2154.361    3056.3881\n  3956.07145  7526.70645 34439.8559  12928.7911   7152.6714  26236.57997\n 11743.9341   1769.53165 10825.2537  10796.35025  4296.2712   1632.03625\n 44202.6536   7623.518   28340.18885  3594.17085 24513.09126  5488.262\n 11842.442   17748.5062  33900.653    9566.9909   8017.06115  1711.0268\n  4239.89265  8302.53565  2130.6759   9855.1314   1743.214    3392.3652\n 40103.89     6250.435    7265.7025   3989.841   21195.818   10407.08585\n 12797.20962  4934.705    6123.5688   4915.05985  1534.3045   8703.456\n 21677.28345  5116.5004  46200.9851   9957.7216   6775.961    3046.062\n  6360.9936  39722.7462   1906.35825 11737.84884  8835.26495  8520.026\n  2217.6012  11938.25595 13047.33235 35585.576   12124.9924   7443.64305\n 13393.756   14254.6082  36307.7983   8023.13545 11353.2276  20462.99766\n  3645.0894  35595.5898   4673.3922  19350.3689  18806.14547  4399.731\n 10560.4917  10579.711    5397.6167   1967.0227   1146.7966   1639.5631\n  3227.1211   1731.677   13430.265    3213.62205  7348.142    9048.0273\n 11743.299    6571.02435 12557.6053   2196.4732   9174.13565  5138.2567\n  7421.19455 12363.547   11840.77505 20745.9891  13063.883    8062.764\n  7256.7231  26392.26029  5385.3379  11033.6617   7077.1894   5266.3656\n 21880.82    10713.644    9634.538   12913.9924  10269.46     5125.2157\n  3484.331    5080.096    6402.29135  1704.70015  7243.8136   3201.24515\n  5267.81815 12235.8392   3554.203    3766.8838   2219.4451   2302.3\n  4347.02335 18157.876   22395.74424 36950.2567  12957.118    9872.701\n 44423.803    1634.5734  12430.95335  1615.7667   5253.524   17178.6824\n 10106.13425  5227.98875 13635.6379  10065.413   39597.4072  30166.61817\n  6112.35295 12044.342   19444.2658   1631.8212   8604.48365  3994.1778\n  1621.8827  24667.419   33307.5508  20781.48892 14358.36437  6985.50695\n 24393.6224  24869.8368   8240.5896  17179.522   39774.2763   4340.4409\n 23807.2406   8601.3293  24535.69855 17560.37975 12622.1795   9563.029\n 16796.41194 13228.84695 35160.13457  2211.13075 10450.552   11411.685\n  2203.73595  6311.952   24873.3849   1694.7964   2473.3341  11015.1747\n 13143.33665  6653.7886   1121.8739  60021.39897  1980.07    10977.2063\n 20177.67113  2483.736    4536.259   25992.82104 16455.70785  6128.79745\n 46599.1084  32108.66282 11658.11505  1826.843    9866.30485 16138.76205\n  5920.1041   2026.9741   7418.522   15006.57945  7639.41745 11520.09985\n  9095.06825 12646.207    4134.08245  1621.3402   1515.3449  34806.4677\n  6272.4772  13880.949    3353.284   41661.602    1748.774    7640.3092\n  8891.1395  11362.755    7742.1098   1728.897    6799.458   10923.9332\n  8538.28845  2416.955   18648.4217  12574.049   11381.3254   2156.7518\n  3947.4131  12629.8967   1984.4533   3471.4096   5257.50795 13429.0354\n  1664.9996   9182.17     2801.2588   2304.0022   7209.4918   4074.4537\n  2709.1119  12629.1656   8782.469   47896.79135 10085.846   38245.59327\n 15518.18025 13937.6665   6770.1925   4931.647    3393.35635  8688.85885\n 15230.32405  4415.1588   2710.82855  2897.3235  10436.096    3761.292\n 13204.28565  8968.33     6600.20595 12233.828   27037.9141  11830.6072\n 11454.0215  19040.876    2395.17155  2913.569    7633.7206   1141.4451\n  6414.178    1135.9407   6184.2994  20167.33603  8124.4084   4350.5144\n  4032.2407  13405.3903   3500.6123   2007.945    1632.56445  8582.3023\n  8442.667    2755.02095  5699.8375   4889.9995   8522.003   41676.0811\n  4618.0799   1261.859   11150.78     6686.4313   7144.86265 21232.18226\n  9225.2564   3693.428    4149.736   17929.30337 34472.841   12829.4551\n  7196.867    3875.7341   1625.43375 15359.1045   3943.5954   3077.0955\n  3171.6149  17904.52705 15161.5344  47055.5321  36580.28216 27000.98473\n  1880.07    17468.9839  11326.71487  6435.6237   6356.2707   1263.249\n  8116.68    46130.5265  17352.6803   2020.5523  13462.52    38282.7495\n  5469.0066  18765.87545 24671.66334  7740.337    8603.8234   6948.7008\n  2850.68375 12129.61415 27322.73386  3385.39915 11881.9696  14235.072\n 15817.9857  14382.70905 18259.216   18328.2381   6748.5912   9283.562\n 43896.3763  10338.9316   8823.279   11253.421    7345.7266   6186.127\n  4661.28635 25081.76784 18246.4955  19144.57652 11488.31695  1242.26\n  5012.471    2138.0707  10594.2257   7749.1564   7153.5539  37607.5277\n  9861.025    1526.312   24476.47851 11244.3769   5240.765   12644.589\n 10422.91665  9411.005    6666.243    5003.853    1877.9294  49577.6624\n 14394.5579  12495.29085  5584.3057   3579.8287  11070.535   14133.03775\n 15828.82173 10381.4787   1137.011    1391.5287   8233.0975   3392.9768\n  4779.6023  10197.7722  12890.05765 16115.3045   2134.9015   4337.7352\n  4454.40265  8027.968   27724.28875  9504.3103  12485.8009  18033.9679\n 43753.33705  3260.199   44400.4064  12609.88702  8083.9198   5272.1758\n  4076.497   37079.372   11163.568    9910.35985  5246.047    2104.1134\n 16069.08475 20773.62775  3167.45585  6358.77645  1163.4627  10791.96\n 10848.1343   4237.12655  4992.3764  12105.32    16420.49455 14410.9321\n 36189.1017  13470.86     7726.854   11082.5772   8569.8618   8068.185\n 14449.8544  16884.924   39983.42595  9863.4718   8964.06055 35147.52848\n  2632.992    3857.75925  3877.30425  8334.45755 46661.4424  39727.614\n 34779.615   11363.2832  42760.5022  48673.5588  21344.8467  17043.3414\n  3659.346   28868.6639   5002.7827  10264.4421   2155.6815  42111.6647\n 12648.7034   7201.70085 12096.6512   4571.41305  9288.0267  36124.5737\n  6548.19505 16450.8947   9778.3472   1832.094   40419.0191  14451.83515\n  4402.233    9625.92    18608.262    7160.094    2585.269    2020.177\n  8965.79575 21984.47061  2457.21115 11657.7189  24603.04837 42112.2356\n 10976.24575  2459.7201   3704.3545  21259.37795  9487.6442   2221.56445\n 43813.8661   7358.17565 44641.1974   4466.6214  11987.1682   2689.4954\n 36021.0112   3481.868    9748.9106  10072.05505  8232.6388  28950.4692\n 11289.10925 16085.1275  30063.58055 46151.1245   4686.3887  21774.32215\n 12032.326    4133.64165  5979.731   10928.849   10043.249    4463.2051\n  9800.8882   1628.4709   4646.759   10704.47     2904.088   12925.886\n 58571.07448  9414.92    17081.08    33750.2918  10325.206   10959.6947\n 11264.541    2480.9791  21659.9301  14119.62    19798.05455  3577.999\n  2045.68525 38344.566    7281.5056  22218.1149  24106.91255 39047.285\n  1977.815   27117.99378 12029.2867   6289.7549  38711.      19594.80965\n  8539.671   37829.7242   9620.3307  12404.8791   5209.57885 19964.7463\n  6373.55735 13887.204   13981.85035 19442.3535   2207.69745  3866.8552\n 22331.5668   4357.04365 13725.47184 11931.12525 13607.36875  9264.797\n  4753.6368  14474.675   20878.78443 23288.9284   5708.867   34672.1472\n 26926.5144   8551.347    6986.697    7624.63     2438.0552   5974.3847\n 13831.1152  37484.4493   9875.6804   8125.7845   2709.24395 11090.7178\n  1712.227   10156.7832  13390.559   13844.7972   6059.173   11674.13\n  5152.134   12142.5786   5989.52365  5615.369    4762.329    1875.344\n 11394.06555  2250.8352  13126.67745  5926.846   12741.16745  6849.026\n  7162.0122  55135.40209  4438.2634   3861.20965  9549.5651   5478.0368\n 11286.5387   9850.432   11165.41765  9101.798    8527.532   31620.00106\n  8252.2843   8823.98575 29330.98315  2497.0383   7046.7222  48549.17835\n 10096.97     4234.927   12146.971    4719.73655 47462.894   39725.51805\n 21797.0004   1242.816    9877.6077  21348.706   19539.243   10965.446\n  4527.18295  2396.0959  11365.952    3558.62025  5028.1466   2331.519\n 20234.85475 23306.547   41949.2441   9144.565   15555.18875  8211.1002\n 47269.854    5729.0053   3309.7926  12638.195    6313.759   46113.511\n 11305.93455  7518.02535  1727.54     2464.6188   4747.0529  11842.62375\n 19719.6947   8334.5896   3292.52985 17663.1442  21082.16    11455.28\n 18955.22017 10564.8845  40720.55105 25309.489   38792.6856   3044.2133\n  8671.19125  6455.86265  1815.8759   2719.27975 18963.17192  4795.6568\n  6082.405    4922.9159   1261.442   23563.01618 13555.0049   8516.829\n  3172.018   15612.19335  7050.642    1727.785   10141.1362  13770.0979\n 24180.9335  34828.654   14349.8544   6600.361   13352.0998  19023.26\n 14901.5167  18804.7524  19496.71917 26140.3603  19361.9988   5245.2269\n 21978.6769  11946.6259   2136.88225 11538.421   19933.458    1702.4553\n  2680.9493   1136.3994   6198.7518  34617.84065  3537.703   12094.478\n  5373.36425 12224.35085 16657.71745  9541.69555 42211.1382  22462.04375\n  6710.1919  24915.22085  9704.66805  6389.37785  6203.90175 10355.641\n 11013.7119   9583.8933   5630.45785 11881.358    4830.63     2741.948\n 20984.0936   2523.1695   4949.7587   8428.0693  11482.63485 14256.1928\n  2201.0971   1705.6245  10600.5483  13470.8044   6185.3208   7954.517\n 27218.43725 41999.52    14001.1338  19673.33573  1842.519   25333.33284\n 23887.6627  29186.48236 27533.9129  11945.1327   7441.501    8798.593\n  2166.732    3062.50825  8627.5411  11566.30055 11735.87905  7512.267\n 25678.77845  3161.454   16297.846   47291.055   10806.839   24915.04626\n  9432.9253  48885.13561 26109.32905  6393.60345  9715.841   28476.73499\n 40941.2854  36910.60803  4687.797   20420.60465  4151.0287  27941.28758\n 27808.7251   5966.8874   5757.41345 43578.9394   5934.3798   1981.5819\n  7050.0213   5855.9025   7045.499    9386.1613   2494.022    6610.1097\n 11093.6229  44585.45587  5709.1644  39556.4945  14007.222    6238.298\n 22412.6485  38126.2465  12815.44495 37701.8768   6474.013    3847.674\n 13415.0381   5846.9176   8871.1517  35069.37452  8116.26885  1759.338\n 30284.64294  2842.76075 43921.1837   6593.5083   5693.4305   4827.90495\n  9193.8385  36085.219   17496.306   12231.6136   1252.407   20009.63365\n  1241.565    4529.477   18223.4512  13129.60345  2527.81865  7228.21565\n  3208.787   13974.45555 26467.09737  7261.741    2866.091   37133.8982\n 39836.519    7173.35995 15170.069    6571.544   14988.432   10942.13205\n  8988.15875 23082.95533  9869.8102   6338.0756  20277.80751 34303.1672\n  5400.9805   1682.597   62592.87309  8978.1851   3176.8159  13822.803\n  9617.66245  7985.815    2102.2647   7133.9025  32734.1863   2103.08\n  2775.19215 38415.474    2585.85065 11763.0009   7222.78625  7789.635\n 29523.1656   2457.502   63770.42801 10231.4999  12949.1554  40273.6455\n  7147.4728   2727.3951   2639.0429  22478.6     14394.39815  4719.52405\n 11272.33139  8733.22925 15820.699   37270.1512   5910.944    5031.26955\n  7804.1605  30259.99556  7448.40395 11741.726   45008.9555   8825.086\n 10601.63225  2855.43755 11073.176    3972.9247   5375.038   34838.873\n  1633.0444  11299.343   33471.97189  2150.469   13747.87235  3070.8087\n  7160.3303   5415.6612   1646.4297   4766.022  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m scy\u001b[38;5;241m=\u001b[39mStandardScaler()\n\u001b[1;32m----> 2\u001b[0m y_train\u001b[38;5;241m=\u001b[39mscy\u001b[38;5;241m.\u001b[39mfit_transform(y_train)\n\u001b[0;32m      3\u001b[0m y_test\u001b[38;5;241m=\u001b[39mscy\u001b[38;5;241m.\u001b[39mtransform(y_test)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 873\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    874\u001b[0m     X,\n\u001b[0;32m    875\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    876\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    877\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    878\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1622.1885  41919.097    8944.1151   4391.652    4005.4225   8930.93455\n  9447.25035  7731.85785 11576.13     3757.8448   2154.361    3056.3881\n  3956.07145  7526.70645 34439.8559  12928.7911   7152.6714  26236.57997\n 11743.9341   1769.53165 10825.2537  10796.35025  4296.2712   1632.03625\n 44202.6536   7623.518   28340.18885  3594.17085 24513.09126  5488.262\n 11842.442   17748.5062  33900.653    9566.9909   8017.06115  1711.0268\n  4239.89265  8302.53565  2130.6759   9855.1314   1743.214    3392.3652\n 40103.89     6250.435    7265.7025   3989.841   21195.818   10407.08585\n 12797.20962  4934.705    6123.5688   4915.05985  1534.3045   8703.456\n 21677.28345  5116.5004  46200.9851   9957.7216   6775.961    3046.062\n  6360.9936  39722.7462   1906.35825 11737.84884  8835.26495  8520.026\n  2217.6012  11938.25595 13047.33235 35585.576   12124.9924   7443.64305\n 13393.756   14254.6082  36307.7983   8023.13545 11353.2276  20462.99766\n  3645.0894  35595.5898   4673.3922  19350.3689  18806.14547  4399.731\n 10560.4917  10579.711    5397.6167   1967.0227   1146.7966   1639.5631\n  3227.1211   1731.677   13430.265    3213.62205  7348.142    9048.0273\n 11743.299    6571.02435 12557.6053   2196.4732   9174.13565  5138.2567\n  7421.19455 12363.547   11840.77505 20745.9891  13063.883    8062.764\n  7256.7231  26392.26029  5385.3379  11033.6617   7077.1894   5266.3656\n 21880.82    10713.644    9634.538   12913.9924  10269.46     5125.2157\n  3484.331    5080.096    6402.29135  1704.70015  7243.8136   3201.24515\n  5267.81815 12235.8392   3554.203    3766.8838   2219.4451   2302.3\n  4347.02335 18157.876   22395.74424 36950.2567  12957.118    9872.701\n 44423.803    1634.5734  12430.95335  1615.7667   5253.524   17178.6824\n 10106.13425  5227.98875 13635.6379  10065.413   39597.4072  30166.61817\n  6112.35295 12044.342   19444.2658   1631.8212   8604.48365  3994.1778\n  1621.8827  24667.419   33307.5508  20781.48892 14358.36437  6985.50695\n 24393.6224  24869.8368   8240.5896  17179.522   39774.2763   4340.4409\n 23807.2406   8601.3293  24535.69855 17560.37975 12622.1795   9563.029\n 16796.41194 13228.84695 35160.13457  2211.13075 10450.552   11411.685\n  2203.73595  6311.952   24873.3849   1694.7964   2473.3341  11015.1747\n 13143.33665  6653.7886   1121.8739  60021.39897  1980.07    10977.2063\n 20177.67113  2483.736    4536.259   25992.82104 16455.70785  6128.79745\n 46599.1084  32108.66282 11658.11505  1826.843    9866.30485 16138.76205\n  5920.1041   2026.9741   7418.522   15006.57945  7639.41745 11520.09985\n  9095.06825 12646.207    4134.08245  1621.3402   1515.3449  34806.4677\n  6272.4772  13880.949    3353.284   41661.602    1748.774    7640.3092\n  8891.1395  11362.755    7742.1098   1728.897    6799.458   10923.9332\n  8538.28845  2416.955   18648.4217  12574.049   11381.3254   2156.7518\n  3947.4131  12629.8967   1984.4533   3471.4096   5257.50795 13429.0354\n  1664.9996   9182.17     2801.2588   2304.0022   7209.4918   4074.4537\n  2709.1119  12629.1656   8782.469   47896.79135 10085.846   38245.59327\n 15518.18025 13937.6665   6770.1925   4931.647    3393.35635  8688.85885\n 15230.32405  4415.1588   2710.82855  2897.3235  10436.096    3761.292\n 13204.28565  8968.33     6600.20595 12233.828   27037.9141  11830.6072\n 11454.0215  19040.876    2395.17155  2913.569    7633.7206   1141.4451\n  6414.178    1135.9407   6184.2994  20167.33603  8124.4084   4350.5144\n  4032.2407  13405.3903   3500.6123   2007.945    1632.56445  8582.3023\n  8442.667    2755.02095  5699.8375   4889.9995   8522.003   41676.0811\n  4618.0799   1261.859   11150.78     6686.4313   7144.86265 21232.18226\n  9225.2564   3693.428    4149.736   17929.30337 34472.841   12829.4551\n  7196.867    3875.7341   1625.43375 15359.1045   3943.5954   3077.0955\n  3171.6149  17904.52705 15161.5344  47055.5321  36580.28216 27000.98473\n  1880.07    17468.9839  11326.71487  6435.6237   6356.2707   1263.249\n  8116.68    46130.5265  17352.6803   2020.5523  13462.52    38282.7495\n  5469.0066  18765.87545 24671.66334  7740.337    8603.8234   6948.7008\n  2850.68375 12129.61415 27322.73386  3385.39915 11881.9696  14235.072\n 15817.9857  14382.70905 18259.216   18328.2381   6748.5912   9283.562\n 43896.3763  10338.9316   8823.279   11253.421    7345.7266   6186.127\n  4661.28635 25081.76784 18246.4955  19144.57652 11488.31695  1242.26\n  5012.471    2138.0707  10594.2257   7749.1564   7153.5539  37607.5277\n  9861.025    1526.312   24476.47851 11244.3769   5240.765   12644.589\n 10422.91665  9411.005    6666.243    5003.853    1877.9294  49577.6624\n 14394.5579  12495.29085  5584.3057   3579.8287  11070.535   14133.03775\n 15828.82173 10381.4787   1137.011    1391.5287   8233.0975   3392.9768\n  4779.6023  10197.7722  12890.05765 16115.3045   2134.9015   4337.7352\n  4454.40265  8027.968   27724.28875  9504.3103  12485.8009  18033.9679\n 43753.33705  3260.199   44400.4064  12609.88702  8083.9198   5272.1758\n  4076.497   37079.372   11163.568    9910.35985  5246.047    2104.1134\n 16069.08475 20773.62775  3167.45585  6358.77645  1163.4627  10791.96\n 10848.1343   4237.12655  4992.3764  12105.32    16420.49455 14410.9321\n 36189.1017  13470.86     7726.854   11082.5772   8569.8618   8068.185\n 14449.8544  16884.924   39983.42595  9863.4718   8964.06055 35147.52848\n  2632.992    3857.75925  3877.30425  8334.45755 46661.4424  39727.614\n 34779.615   11363.2832  42760.5022  48673.5588  21344.8467  17043.3414\n  3659.346   28868.6639   5002.7827  10264.4421   2155.6815  42111.6647\n 12648.7034   7201.70085 12096.6512   4571.41305  9288.0267  36124.5737\n  6548.19505 16450.8947   9778.3472   1832.094   40419.0191  14451.83515\n  4402.233    9625.92    18608.262    7160.094    2585.269    2020.177\n  8965.79575 21984.47061  2457.21115 11657.7189  24603.04837 42112.2356\n 10976.24575  2459.7201   3704.3545  21259.37795  9487.6442   2221.56445\n 43813.8661   7358.17565 44641.1974   4466.6214  11987.1682   2689.4954\n 36021.0112   3481.868    9748.9106  10072.05505  8232.6388  28950.4692\n 11289.10925 16085.1275  30063.58055 46151.1245   4686.3887  21774.32215\n 12032.326    4133.64165  5979.731   10928.849   10043.249    4463.2051\n  9800.8882   1628.4709   4646.759   10704.47     2904.088   12925.886\n 58571.07448  9414.92    17081.08    33750.2918  10325.206   10959.6947\n 11264.541    2480.9791  21659.9301  14119.62    19798.05455  3577.999\n  2045.68525 38344.566    7281.5056  22218.1149  24106.91255 39047.285\n  1977.815   27117.99378 12029.2867   6289.7549  38711.      19594.80965\n  8539.671   37829.7242   9620.3307  12404.8791   5209.57885 19964.7463\n  6373.55735 13887.204   13981.85035 19442.3535   2207.69745  3866.8552\n 22331.5668   4357.04365 13725.47184 11931.12525 13607.36875  9264.797\n  4753.6368  14474.675   20878.78443 23288.9284   5708.867   34672.1472\n 26926.5144   8551.347    6986.697    7624.63     2438.0552   5974.3847\n 13831.1152  37484.4493   9875.6804   8125.7845   2709.24395 11090.7178\n  1712.227   10156.7832  13390.559   13844.7972   6059.173   11674.13\n  5152.134   12142.5786   5989.52365  5615.369    4762.329    1875.344\n 11394.06555  2250.8352  13126.67745  5926.846   12741.16745  6849.026\n  7162.0122  55135.40209  4438.2634   3861.20965  9549.5651   5478.0368\n 11286.5387   9850.432   11165.41765  9101.798    8527.532   31620.00106\n  8252.2843   8823.98575 29330.98315  2497.0383   7046.7222  48549.17835\n 10096.97     4234.927   12146.971    4719.73655 47462.894   39725.51805\n 21797.0004   1242.816    9877.6077  21348.706   19539.243   10965.446\n  4527.18295  2396.0959  11365.952    3558.62025  5028.1466   2331.519\n 20234.85475 23306.547   41949.2441   9144.565   15555.18875  8211.1002\n 47269.854    5729.0053   3309.7926  12638.195    6313.759   46113.511\n 11305.93455  7518.02535  1727.54     2464.6188   4747.0529  11842.62375\n 19719.6947   8334.5896   3292.52985 17663.1442  21082.16    11455.28\n 18955.22017 10564.8845  40720.55105 25309.489   38792.6856   3044.2133\n  8671.19125  6455.86265  1815.8759   2719.27975 18963.17192  4795.6568\n  6082.405    4922.9159   1261.442   23563.01618 13555.0049   8516.829\n  3172.018   15612.19335  7050.642    1727.785   10141.1362  13770.0979\n 24180.9335  34828.654   14349.8544   6600.361   13352.0998  19023.26\n 14901.5167  18804.7524  19496.71917 26140.3603  19361.9988   5245.2269\n 21978.6769  11946.6259   2136.88225 11538.421   19933.458    1702.4553\n  2680.9493   1136.3994   6198.7518  34617.84065  3537.703   12094.478\n  5373.36425 12224.35085 16657.71745  9541.69555 42211.1382  22462.04375\n  6710.1919  24915.22085  9704.66805  6389.37785  6203.90175 10355.641\n 11013.7119   9583.8933   5630.45785 11881.358    4830.63     2741.948\n 20984.0936   2523.1695   4949.7587   8428.0693  11482.63485 14256.1928\n  2201.0971   1705.6245  10600.5483  13470.8044   6185.3208   7954.517\n 27218.43725 41999.52    14001.1338  19673.33573  1842.519   25333.33284\n 23887.6627  29186.48236 27533.9129  11945.1327   7441.501    8798.593\n  2166.732    3062.50825  8627.5411  11566.30055 11735.87905  7512.267\n 25678.77845  3161.454   16297.846   47291.055   10806.839   24915.04626\n  9432.9253  48885.13561 26109.32905  6393.60345  9715.841   28476.73499\n 40941.2854  36910.60803  4687.797   20420.60465  4151.0287  27941.28758\n 27808.7251   5966.8874   5757.41345 43578.9394   5934.3798   1981.5819\n  7050.0213   5855.9025   7045.499    9386.1613   2494.022    6610.1097\n 11093.6229  44585.45587  5709.1644  39556.4945  14007.222    6238.298\n 22412.6485  38126.2465  12815.44495 37701.8768   6474.013    3847.674\n 13415.0381   5846.9176   8871.1517  35069.37452  8116.26885  1759.338\n 30284.64294  2842.76075 43921.1837   6593.5083   5693.4305   4827.90495\n  9193.8385  36085.219   17496.306   12231.6136   1252.407   20009.63365\n  1241.565    4529.477   18223.4512  13129.60345  2527.81865  7228.21565\n  3208.787   13974.45555 26467.09737  7261.741    2866.091   37133.8982\n 39836.519    7173.35995 15170.069    6571.544   14988.432   10942.13205\n  8988.15875 23082.95533  9869.8102   6338.0756  20277.80751 34303.1672\n  5400.9805   1682.597   62592.87309  8978.1851   3176.8159  13822.803\n  9617.66245  7985.815    2102.2647   7133.9025  32734.1863   2103.08\n  2775.19215 38415.474    2585.85065 11763.0009   7222.78625  7789.635\n 29523.1656   2457.502   63770.42801 10231.4999  12949.1554  40273.6455\n  7147.4728   2727.3951   2639.0429  22478.6     14394.39815  4719.52405\n 11272.33139  8733.22925 15820.699   37270.1512   5910.944    5031.26955\n  7804.1605  30259.99556  7448.40395 11741.726   45008.9555   8825.086\n 10601.63225  2855.43755 11073.176    3972.9247   5375.038   34838.873\n  1633.0444  11299.343   33471.97189  2150.469   13747.87235  3070.8087\n  7160.3303   5415.6612   1646.4297   4766.022  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "scy=StandardScaler()\n",
    "y_train=scy.fit_transform(y_train)\n",
    "y_test=scy.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c2cfb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;,\n",
       "                                       &#x27;friedman_mse&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;,\n",
       "                                       &#x27;friedman_mse&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error', 'absolute_error',\n",
       "                                       'friedman_mse', 'poisson'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [10, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "param_grid = {'criterion':['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],'max_features': ['sqrt','log2'],'n_estimators':[10,100]}\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid, refit = True, verbose=3,n_jobs=-1)\n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb4927d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R_score value for best parameter {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 100}: 0.8737475411225939\n"
     ]
    }
   ],
   "source": [
    "re=grid.cv_results_\n",
    "grid_predictions = grid.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "r_score=r2_score(y_test,grid_predictions)\n",
    "print(\"The R_score value for best parameter {}:\".format(grid.best_params_),r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba8ee066",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.DataFrame.from_dict(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7518a82e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086002</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.792679</td>\n",
       "      <td>0.750180</td>\n",
       "      <td>0.819146</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.754021</td>\n",
       "      <td>0.782473</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.027082</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.809970</td>\n",
       "      <td>0.773449</td>\n",
       "      <td>0.835826</td>\n",
       "      <td>0.821107</td>\n",
       "      <td>0.767127</td>\n",
       "      <td>0.801496</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065701</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.787034</td>\n",
       "      <td>0.751173</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.810915</td>\n",
       "      <td>0.738796</td>\n",
       "      <td>0.779555</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588868</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.808879</td>\n",
       "      <td>0.775957</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>0.829513</td>\n",
       "      <td>0.764894</td>\n",
       "      <td>0.802323</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145572</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.773771</td>\n",
       "      <td>0.757030</td>\n",
       "      <td>0.819224</td>\n",
       "      <td>0.802767</td>\n",
       "      <td>0.758413</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>0.024755</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.412290</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.019875</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.806347</td>\n",
       "      <td>0.772650</td>\n",
       "      <td>0.834708</td>\n",
       "      <td>0.832456</td>\n",
       "      <td>0.765573</td>\n",
       "      <td>0.802347</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.142480</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.783665</td>\n",
       "      <td>0.744437</td>\n",
       "      <td>0.813145</td>\n",
       "      <td>0.820148</td>\n",
       "      <td>0.748865</td>\n",
       "      <td>0.782052</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.437120</td>\n",
       "      <td>0.044839</td>\n",
       "      <td>0.018629</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.805721</td>\n",
       "      <td>0.778933</td>\n",
       "      <td>0.839046</td>\n",
       "      <td>0.832489</td>\n",
       "      <td>0.765652</td>\n",
       "      <td>0.804368</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.797149</td>\n",
       "      <td>0.744603</td>\n",
       "      <td>0.828830</td>\n",
       "      <td>0.787378</td>\n",
       "      <td>0.734032</td>\n",
       "      <td>0.778398</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.588369</td>\n",
       "      <td>0.022576</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.807464</td>\n",
       "      <td>0.760121</td>\n",
       "      <td>0.842084</td>\n",
       "      <td>0.820150</td>\n",
       "      <td>0.764452</td>\n",
       "      <td>0.798854</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.064155</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.790710</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.825426</td>\n",
       "      <td>0.798570</td>\n",
       "      <td>0.739004</td>\n",
       "      <td>0.786952</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.602208</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>0.022711</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.803884</td>\n",
       "      <td>0.761647</td>\n",
       "      <td>0.836069</td>\n",
       "      <td>0.829634</td>\n",
       "      <td>0.759959</td>\n",
       "      <td>0.798239</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.069640</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>0.787510</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.822263</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.723215</td>\n",
       "      <td>0.779655</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.664782</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.024747</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>0.800356</td>\n",
       "      <td>0.764461</td>\n",
       "      <td>0.830652</td>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.757028</td>\n",
       "      <td>0.796851</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>0.777458</td>\n",
       "      <td>0.766797</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.813945</td>\n",
       "      <td>0.748186</td>\n",
       "      <td>0.784164</td>\n",
       "      <td>0.026246</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.532657</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>0.804670</td>\n",
       "      <td>0.778495</td>\n",
       "      <td>0.838875</td>\n",
       "      <td>0.832450</td>\n",
       "      <td>0.761422</td>\n",
       "      <td>0.803182</td>\n",
       "      <td>0.029954</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.086002      0.012116         0.003125        0.006250   \n",
       "1        0.630851      0.027082         0.021870        0.007632   \n",
       "2        0.065701      0.006275         0.005009        0.006135   \n",
       "3        0.588868      0.007395         0.028351        0.006578   \n",
       "4        0.145572      0.011906         0.003428        0.006856   \n",
       "5        1.412290      0.022690         0.019875        0.006213   \n",
       "6        0.142480      0.010354         0.003128        0.006256   \n",
       "7        1.437120      0.044839         0.018629        0.006311   \n",
       "8        0.057514      0.008596         0.006253        0.007659   \n",
       "9        0.588369      0.022576         0.021854        0.007628   \n",
       "10       0.064155      0.002688         0.000000        0.000000   \n",
       "11       0.602208      0.016385         0.022711        0.007529   \n",
       "12       0.069640      0.007214         0.003126        0.006252   \n",
       "13       0.664782      0.014947         0.024747        0.007153   \n",
       "14       0.069170      0.007496         0.006257        0.007663   \n",
       "15       0.532657      0.064827         0.015744        0.000220   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0    squared_error               sqrt                 10   \n",
       "1    squared_error               sqrt                100   \n",
       "2    squared_error               log2                 10   \n",
       "3    squared_error               log2                100   \n",
       "4   absolute_error               sqrt                 10   \n",
       "5   absolute_error               sqrt                100   \n",
       "6   absolute_error               log2                 10   \n",
       "7   absolute_error               log2                100   \n",
       "8     friedman_mse               sqrt                 10   \n",
       "9     friedman_mse               sqrt                100   \n",
       "10    friedman_mse               log2                 10   \n",
       "11    friedman_mse               log2                100   \n",
       "12         poisson               sqrt                 10   \n",
       "13         poisson               sqrt                100   \n",
       "14         poisson               log2                 10   \n",
       "15         poisson               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'squared_error', 'max_features':...           0.792679   \n",
       "1   {'criterion': 'squared_error', 'max_features':...           0.809970   \n",
       "2   {'criterion': 'squared_error', 'max_features':...           0.787034   \n",
       "3   {'criterion': 'squared_error', 'max_features':...           0.808879   \n",
       "4   {'criterion': 'absolute_error', 'max_features'...           0.773771   \n",
       "5   {'criterion': 'absolute_error', 'max_features'...           0.806347   \n",
       "6   {'criterion': 'absolute_error', 'max_features'...           0.783665   \n",
       "7   {'criterion': 'absolute_error', 'max_features'...           0.805721   \n",
       "8   {'criterion': 'friedman_mse', 'max_features': ...           0.797149   \n",
       "9   {'criterion': 'friedman_mse', 'max_features': ...           0.807464   \n",
       "10  {'criterion': 'friedman_mse', 'max_features': ...           0.790710   \n",
       "11  {'criterion': 'friedman_mse', 'max_features': ...           0.803884   \n",
       "12  {'criterion': 'poisson', 'max_features': 'sqrt...           0.787510   \n",
       "13  {'criterion': 'poisson', 'max_features': 'sqrt...           0.800356   \n",
       "14  {'criterion': 'poisson', 'max_features': 'log2...           0.777458   \n",
       "15  {'criterion': 'poisson', 'max_features': 'log2...           0.804670   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.750180           0.819146           0.796338   \n",
       "1            0.773449           0.835826           0.821107   \n",
       "2            0.751173           0.809855           0.810915   \n",
       "3            0.775957           0.832370           0.829513   \n",
       "4            0.757030           0.819224           0.802767   \n",
       "5            0.772650           0.834708           0.832456   \n",
       "6            0.744437           0.813145           0.820148   \n",
       "7            0.778933           0.839046           0.832489   \n",
       "8            0.744603           0.828830           0.787378   \n",
       "9            0.760121           0.842084           0.820150   \n",
       "10           0.781049           0.825426           0.798570   \n",
       "11           0.761647           0.836069           0.829634   \n",
       "12           0.755920           0.822263           0.809365   \n",
       "13           0.764461           0.830652           0.831758   \n",
       "14           0.766797           0.814433           0.813945   \n",
       "15           0.778495           0.838875           0.832450   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.754021         0.782473        0.026433               11  \n",
       "1            0.767127         0.801496        0.026843                5  \n",
       "2            0.738796         0.779555        0.029747               15  \n",
       "3            0.764894         0.802323        0.027500                4  \n",
       "4            0.758413         0.782241        0.024755               12  \n",
       "5            0.765573         0.802347        0.028997                3  \n",
       "6            0.748865         0.782052        0.031423               13  \n",
       "7            0.765652         0.804368        0.028779                1  \n",
       "8            0.734032         0.778398        0.034888               16  \n",
       "9            0.764452         0.798854        0.031875                6  \n",
       "10           0.739004         0.786952        0.028154                9  \n",
       "11           0.759959         0.798239        0.032413                7  \n",
       "12           0.723215         0.779655        0.036079               14  \n",
       "13           0.757028         0.796851        0.031649                8  \n",
       "14           0.748186         0.784164        0.026246               10  \n",
       "15           0.761422         0.803182        0.029954                2  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9851cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"finalized_advancedtechniqueRF.sav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0036a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90f264ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preinput=sc.transform([[age_input,bmi_input,children_input,sex_male_input,smoker_yes_input]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d128052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:25\n",
      "BMI:45\n",
      "Children:2\n",
      "Sex Male 0 or 1:1\n",
      "Smoker Yes 0 or 1:1\n"
     ]
    }
   ],
   "source": [
    "age_input=float(input(\"Age:\"))\n",
    "bmi_input=float(input(\"BMI:\"))\n",
    "children_input=float(input(\"Children:\"))\n",
    "sex_male_input=int(input(\"Sex Male 0 or 1:\"))\n",
    "smoker_yes_input=int(input(\"Smoker Yes 0 or 1:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3cd7f5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.03919296,  2.31963086,  0.75672907,  1.01127431,  2.00280702]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d2b2820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_advancedtechniqueRF.sav\", 'rb'))\n",
    "result=loaded_model.predict(preinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93a4af2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40338.2413169])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
